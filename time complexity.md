## What is "Big O" (O-notation)?
"Big O" tells us how fast or slow a program grows as input size increases.

It ignores small things (like 2 seconds vs 3 seconds) and focuses on the trend.

It only cares about the biggest factor when n (input size) becomes large.

ğŸ“š ### Common Time Complexities

Name	O-notation	Meaning
Constant Time	O(1)	No matter the input size, it takes the same time.
Linear Time	O(n)	Time grows directly with input size.
Logarithmic Time	O(log n)	Time grows slowly even if input size is big.
Linearithmic Time	O(n log n)	Grows faster than O(n), but slower than O(nÂ²).
Quadratic Time	O(nÂ²)	Time grows with square of input size.
Cubic Time	O(nÂ³)	Time grows with cube of input size.
Exponential Time	O(2â¿)	Time doubles with each extra input.
ğŸ› ï¸ 1. O(1) - Constant Time
Meaning: Always takes the same time, no matter how big the input is.

Example:

```python

def get_first_element(arr):
    return arr[0]
```
Whether arr has 10 elements or 1 million, picking the first element is just 1 step.

âœ… Time = O(1)

ğŸ› ï¸ 2. O(n) - Linear Time
Meaning: Time grows directly with input size.

Example:

```python

def print_all_elements(arr):
    for element in arr:
        print(element)
```
If arr has 10 elements â” 10 prints.

If arr has 1000 elements â” 1000 prints.

âœ… Time = O(n)

ğŸ› ï¸ 3. O(nÂ²) - Quadratic Time
Meaning: Time grows as the square of input size. (n Ã— n)

Example:

python
Copy
Edit
def print_pairs(arr):
    for i in arr:
        for j in arr:
            print(i, j)
If arr has 5 elements â” 5 Ã— 5 = 25 pairs.

If arr has 100 elements â” 100 Ã— 100 = 10,000 pairs!

âœ… Time = O(nÂ²)

ğŸ§  Rule: Nested loops = Often O(nÂ²)

ğŸ› ï¸ 4. O(log n) - Logarithmic Time
Meaning: Time grows very slowly, even if input grows fast.

Example:

python
Copy
Edit
def binary_search(arr, target):
    low = 0
    high = len(arr) - 1
    while low <= high:
        mid = (low + high) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            low = mid + 1
        else:
            high = mid - 1
    return -1
You divide the list by half each time.

Searching in 1,000,000 elements = only about 20 steps!

âœ… Time = O(log n)

ğŸ“š Memory Tip:
"Every step cuts work in half = O(log n)"

ğŸ› ï¸ 5. O(n log n) - Linearithmic Time
Meaning: A little slower than O(n), but much faster than O(nÂ²).

Example:

Merge Sort or Heap Sort algorithms.

Real-world example: Sorting a huge list.

python
Copy
Edit
# Merge sort (concept)
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)
âœ… Time = O(n log n)

Splitting is log n.

Merging all items is n.

Together â” O(n log n).

ğŸ¨ Quick Visual Feeling (How Fast They Grow)

n = 10	n = 100	n = 1000
O(1)	1	1
O(log n)	3	6
O(n)	10	100
O(n log n)	30	600
O(nÂ²)	100	10,000
O(2â¿)	1024	(impossible huge)
ğŸ§  Easy Memory Trick ğŸ¯

O(1)	Instant
O(log n)	Cuts in half again and again
O(n)	1 step for 1 item
O(n log n)	1 step + half splits
O(nÂ²)	Compare everything to everything
ğŸ”¥ Summary Table

Name	Common Example	Time Growth
O(1)	Accessing first element	ğŸš€ Very Fast
O(n)	For loop through list	ğŸƒâ€â™‚ï¸ Grows with input
O(log n)	Binary search	ğŸ¢ Very Slow Growth
O(n log n)	Merge Sort	âš¡ Medium
O(nÂ²)	Nested loops (compare all)	ğŸ˜ Slow
